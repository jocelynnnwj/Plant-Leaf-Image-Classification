# -*- coding: utf-8 -*-
"""SAM_PlantVillage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cNfZxdNqmFFyQnt7TcftDavZ2B7kzsxr
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
! pip install git+https://github.com/facebookresearch/segment-anything.git
# Clone the SAM repository
!git clone https://github.com/facebookresearch/segment-anything.git
# %cd segment-anything
! pip install -e .
! pip install opencv-python pycocotools matplotlib onnxruntime onnx

# Download SAM pre-trained weights (ViT-H model)
!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth -O sam_vit_h.pth

import torch
from segment_anything import SamAutomaticMaskGenerator, sam_model_registry
from PIL import Image
import numpy as np
import cv2
import os
import matplotlib.pyplot as plt

def show_anns(anns):
    if len(anns) == 0:
        return
    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)
    ax = plt.gca()
    ax.set_autoscale_on(False)

    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))
    img[:,:,3] = 0
    for ann in sorted_anns:
        m = ann['segmentation']
        color_mask = np.concatenate([np.random.random(3), [0.35]])
        img[m] = color_mask
    ax.imshow(img)

# mask_generator = SamAutomaticMaskGenerator(sam) 没有tunable parameters，default
import sys
sys.path.append("..")
# Load the SAM model with pre-trained weights
model_type = "vit_h"  # Options are 'vit_h', 'vit_l', and 'vit_b'
sam_checkpoint = "/content/segment-anything/sam_vit_h.pth"
sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)
sam.to("cuda")  # Move model to GPU if available
# Set up the automatic mask generator
mask_generator = SamAutomaticMaskGenerator(sam)

import numpy as np
from PIL import Image
import torch
from segment_anything import SamPredictor, sam_model_registry
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# Define the path to a single image in Google Drive
image_path = '/content/drive/My Drive/CSCI566/PlantVillage_example/Pepper__bell___Bacterial_spot_2.JPG'

# Function to apply SAM and visualize all masks
def apply_sam_and_visualize_all_masks(image_path):
    # Load the image
    image = Image.open(image_path).convert("RGB")
    image_np = np.array(image)



    # Generate segmentation masks
    masks = mask_generator.generate(image_np)

    # Visualize the original image with masks overlaid
    plt.figure(figsize=(10, 10))
    plt.imshow(image_np)
    plt.title("Original Image with All Masks")
    plt.axis("off")

    # Overlay each mask
    for mask in masks:
        segmentation = mask['segmentation']
        bbox = mask['bbox']  # Bounding box for the mask (x, y, width, height)
        color = np.random.rand(3,)  # Random color for each mask

        # Create a transparency layer for the mask
        masked_area = np.zeros_like(image_np, dtype=np.uint8)
        masked_area[segmentation] = (color * 255).astype(np.uint8)
        plt.imshow(masked_area, alpha=0.5)  # Overlay with transparency

        # Draw the bounding box
        x, y, w, h = bbox
        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor=color, facecolor='none')
        plt.gca().add_patch(rect)

    plt.show()

# Apply SAM and visualize all masks
apply_sam_and_visualize_all_masks(image_path)

# Define the path to a single image in Google Drive
image_path = '/content/drive/My Drive/CSCI566/PlantVillage_example/Pepper__bell___Bacterial_spot_2.JPG'
image = Image.open(image_path).convert("RGB")
image_np = np.array(image)



# Generate segmentation masks
masks = mask_generator.generate(image_np)

# Visualize the original image with masks overlaid
plt.figure(figsize=(10, 10))
plt.imshow(image_np)
plt.title("Original Image with All Masks")
plt.axis("off")

# Define the path to a single image in Google Drive
image_path = '/content/drive/My Drive/CSCI566/PlantVillage_example/Pepper__bell___Bacterial_spot_2.JPG'  # Replace with your image path

# Function to apply SAM segmentation on a single image and keep the largest mask area
def apply_sam_and_isolate_background(image_path):
    # Load the image
    image = Image.open(image_path).convert("RGB")
    image_np = np.array(image)

    # Generate segmentation masks
    masks = mask_generator.generate(image_np)

    # Find the largest mask based on area (assuming it represents the main object)
    largest_mask = max(masks, key=lambda mask: np.sum(mask['segmentation']))
    main_region_mask = largest_mask['segmentation']

    # Create an empty (black) background image
    isolated_main_object = np.zeros_like(image_np)

    # Copy the pixels from the largest mask to the isolated image
    isolated_main_object[main_region_mask] = image_np[main_region_mask]

    return image_np, isolated_main_object

# Apply SAM segmentation and isolate the main object
original_image, isolated_main_object_1 = apply_sam_and_isolate_background(image_path)

# Create a flipped and rotated version of the isolated main object
flipped_and_rotated_object = np.flip(isolated_main_object_1, axis=1)  # Flip horizontally
flipped_and_rotated_object = np.rot90(flipped_and_rotated_object)     # Rotate 90 degrees

# Zoomed-in version of the isolated main object
# Define zoom factor and calculate cropping coordinates
zoom_factor = 0.7  # Adjust this factor as needed
h, w, _ = isolated_main_object_1.shape
crop_h, crop_w = int(h * zoom_factor), int(w * zoom_factor)

# Center crop coordinates
start_y = h // 2 - crop_h // 2
start_x = w // 2 - crop_w // 2
zoomed_object = isolated_main_object_1[start_y:start_y + crop_h, start_x:start_x + crop_w]

# Display the Original, Isolated Main Object, Transformed, and Zoomed-in Images
plt.figure(figsize=(20, 5))

# Original Image
plt.subplot(1, 4, 1)
plt.imshow(original_image)
plt.title("Original Image")
plt.axis("off")

# Isolated Main Object
plt.subplot(1, 4, 2)
plt.imshow(isolated_main_object_1)
plt.title("Main Object (mask_generator)")
plt.axis("off")

# Flipped and Rotated Main Object
plt.subplot(1, 4, 3)
plt.imshow(flipped_and_rotated_object)
plt.title("Flipped and Rotated Object")
plt.axis("off")

# Zoomed-in Main Object
plt.subplot(1, 4, 4)
plt.imshow(zoomed_object)
plt.title("Zoomed-in Main Object")
plt.axis("off")

plt.show()

# 之后再说：Define mask generator parameters
mask_generator_2 = SamAutomaticMaskGenerator(
    model=sam,
    points_per_side=40,                 # Increased for more detailed mask generation
    pred_iou_thresh=0.85,               # Allows for slightly looser masks
    stability_score_thresh=0.9,         # High enough for stable masks, but not overly strict
    crop_n_layers=2,                    # Multiple layers to capture smaller features within main regions
    crop_n_points_downscale_factor=2,   # Balanced detail in cropped areas
    min_mask_region_area=150            # Filters out very small segments
)







#想把每个segment的image都存到新的folder里用于llm

# Path to the folder containing images
image_folder = '/content/drive/My Drive/CSCI566/PlantVillage_example/'  # Replace with your folder path
output_folder = '/content/drive/My Drive/CSCI566/PlantVillage_segmented/'  # Folder to save the segmented images

# Ensure the output folder exists
os.makedirs(output_folder, exist_ok=True)

# Function to apply SAM segmentation and isolate the largest mask
def apply_sam_and_isolate_background(image_path):
    # Load the image
    image = Image.open(image_path).convert("RGB")
    image_np = np.array(image)

    # Generate segmentation masks
    masks = mask_generator.generate(image_np)

    # Find the largest mask based on area (assuming it represents the main object)
    largest_mask = max(masks, key=lambda mask: np.sum(mask['segmentation']))
    main_region_mask = largest_mask['segmentation']

    # Create an empty (black) background image
    isolated_main_object = np.zeros_like(image_np)

    # Copy the pixels from the largest mask to the isolated image
    isolated_main_object[main_region_mask] = image_np[main_region_mask]

    return isolated_main_object

# Loop through each image in the folder
for filename in os.listdir(image_folder):
    if filename.endswith((".jpg", ".jpeg", ".png")):  # Adjust extensions as needed
        image_path = os.path.join(image_folder, filename)

        # Apply SAM segmentation to isolate the main object
        isolated_main_object = apply_sam_and_isolate_background(image_path)

        # Save the isolated main object image to the output folder
        output_path = os.path.join(output_folder, f"segmented_{filename}")
        isolated_image_pil = Image.fromarray(isolated_main_object)
        isolated_image_pil.save(output_path)

        print(f"Processed and saved: {output_path}")